{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import urllib\n",
    "import time\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "place=[\"台北一\"]\n",
    "crop_num=[\"LA1\"]\n",
    "crop_name=[\"甘藍-初秋\"]\n",
    "col_name=[\"date\",\"crop_num\",\"crop_name\",\"market_num\",\"market_name\",\"high\",\"medium\",\"low\",\"mean\",\"volume\"] \n",
    "for a in place:\n",
    "    for b in range(0,len(crop_name)):\n",
    "        df=pd.DataFrame(columns=col_name)\n",
    "        skip_num=0\n",
    "        temp_str=\"\"\n",
    "        for j in range(0,1000): \n",
    "            url=\"https://data.coa.gov.tw/Service/OpenData/FromM/FarmTransData.aspx?$top=1000&$skip=\"+str(skip_num)+\"&Crop=\"+urllib.parse.quote(crop_name[b])+\"&StartDate=101.01.01&EndDate=108.03.29&Market=\"+urllib.parse.quote(a) \n",
    "            get = json.loads(urlopen(url).read().decode('utf-8')) \n",
    "            data = [] \n",
    "            for i in range(0,len(get)):\n",
    "                temp_str=get[0]['交易日期']\n",
    "                Date=get[i]['交易日期'].split('.')\n",
    "                year,month,date=Date[0],Date[1],Date[2]\n",
    "                year=str(int(year)+1911)\n",
    "                get[i]['交易日期']=year+'/'+month+'/'+date\n",
    "                if get[i]['作物代號']==crop_num[b]:\n",
    "                    data.append({\"date\":get[i]['交易日期'],\"crop_num\":get[i]['作物代號'],\"crop_name\":get[i]['作物名稱'],\"market_num\":get[i]['市場代號'],\"market_name\":get[i]['市場名稱'],\"high\":get[i]['上價'],\"medium\":get[i]['中價'],\"low\":get[i]['下價'],\"mean\":get[i]['平均價'],\"volume\":get[i]['交易量']}) \n",
    "                else:\n",
    "                    data.append({\"date\":get[i]['交易日期'],\"crop_num\":get[i]['作物代號'],\"crop_name\":get[i]['作物名稱'],\"market_num\":get[i]['市場代號'],\"market_name\":get[i]['市場名稱'],\"high\":0,\"medium\":0,\"low\":0,\"mean\":0,\"volume\":0}) \n",
    "            data.reverse() \n",
    "            df=pd.concat([pd.DataFrame(data), df], ignore_index=True,sort=True)\n",
    "            if len(get)<1000: \n",
    "                break \n",
    "            skip_num=skip_num+1000 \n",
    "            time.sleep(2000.0/1000.0)\n",
    "        path=r\"C:\\Users\\admin\\Desktop\\Project\\data\"+\"\\\\\"+a+\"\\\\\"+\"蔬果\"+\"\\\\\"+crop_name[b]+\".csv\"\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        #df=df.drop([\"date\"], axis=1)\n",
    "        df.to_csv(\"甘藍-初秋.csv\", encoding='utf_8_sig')\n",
    "        time.sleep(3000.0/1000.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "place_name=[\"雲林\",\"嘉義\",\"彰化\",\"台南\",\"高雄\",\"屏東\",\"台中\",\"苗栗\",\"桃園\",\"台北\"]\n",
    "place_num=[\"C0K240\",\"467480\",\"C0G620\",\"467410\",\"467440\",\"467590\",\"467490\",\"C0E420\",\"C0C480\",\"466920\"]\n",
    "date=[]\n",
    "for year in ['2012','2013','2014','2015','2016','2017','2018']:\n",
    "    for month in ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']:\n",
    "        date.append('-'.join([year,month]))\n",
    "date.append('2019-01')\n",
    "date.append('2019-02')\n",
    "date.append('2019-03')\n",
    "for a in range(0,len(place_name)):\n",
    "    flag=0\n",
    "    name=urllib.parse.quote(urllib.parse.quote(place_name[a]))\n",
    "    for dd in date:\n",
    "        url=\"http://e-service.cwb.gov.tw/HistoryDataQuery/MonthDataController.do?command=viewMain\"+\"&station=\"+place_num[a]+\"&stname=\"+name+\"&datepicker=\"+str(dd)\n",
    "        resp = requests.get(url)\n",
    "        soup = BeautifulSoup(resp.text)\n",
    "        trs = soup.findAll('tr')\n",
    "        ths = trs[2].findAll('th')\n",
    "        day=1\n",
    "        data=[]\n",
    "        fdata=[]\n",
    "        if flag==0:\n",
    "            title=[]\n",
    "            for th in ths:\n",
    "                title.append(th.text)\n",
    "            title.pop(0)\n",
    "            title.append(\"year\")\n",
    "            title.append(\"month\")\n",
    "            title.append(\"day\")\n",
    "            title.append(\"date\")\n",
    "            df=pd.DataFrame(columns=title)\n",
    "            flag=1\n",
    "        for tr in trs[4:]:\n",
    "            t=tr.findAll('td')\n",
    "            for x in t:\n",
    "                data.append(x.text.strip())\n",
    "            sp=dd.split('-')\n",
    "            data.pop(0)\n",
    "            data.append(sp[0])\n",
    "            data.append(sp[1])\n",
    "            data.append(str(day))\n",
    "            data.append(sp[0]+'/'+sp[1]+'/'+str(day))\n",
    "            fdata.append({\"測站氣壓(hPa)\":data[0],\"海平面氣壓(hPa)\":data[1],\"測站最高氣壓(hPa)\":data[2],\"測站最高氣壓時間(LST)\":data[3],\"測站最低氣壓(hPa)\":data[4],\"測站最低氣壓時間(LST)\":data[5],\"氣溫(℃)\":data[6],\"最高氣溫(℃)\":data[7],\"最高氣溫時間(LST)\":data[8],\"最低氣溫(℃)\":data[9],\"最低氣溫時間(LST)\":data[10],\"露點溫度(℃)\":data[11],\"相對溼度(%)\":data[12],\"最小相對溼度(%)\":data[13],\"最小相對溼度時間(LST)\":data[14],\"風速(m/s)\":data[15],\"風向(360degree)\":data[16],\"最大陣風(m/s)\":data[17],\"最大陣風風向(360degree)\":data[18],\"最大陣風風速時間(LST)\":data[19],\"降水量(mm)\":data[20],\"降水時數(hr)\":data[21],\"10分鐘最大降水量(mm)\":data[22],\"10分鐘最大降水起始時間(LST)\":data[23],\" 一小時最大降水量(mm)\":data[24],\"一小時最大降水量起始時間(LST)\":data[25],\"日照時數(hr)\":data[26],\"日照率(%)\":data[27],\"全天空日射量(MJ/㎡)\":data[28],\"能見度(km)\":data[29],\"A型蒸發量(mm)\":data[30],\"日最高紫外線指數\":data[31],\"日最高紫外線指數時間(LST)\":data[32],\"總雲量(0~10)\":data[33],\"year\":data[34],\"month\":data[35],\"day\":data[36],\"date\":data[37]})\n",
    "            day=day+1\n",
    "            data=[]\n",
    "        df=pd.concat([df,pd.DataFrame(fdata)], ignore_index=True,sort=True)\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    path=r\"C:\\Users\\admin\\Desktop\\Project\\test\"+\"\\\\\"+place_name[a]+\".csv\"\n",
    "    df.to_csv(path, encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "place=[\"雲林\",\"嘉義\",\"彰化\",\"台南\",\"高雄\",\"屏東\",\"台中\",\"苗栗\",\"桃園\",\"台北\"]\n",
    "for pl in place:\n",
    "    weather=pd.read_csv(pl+\".csv\")\n",
    "    weather=weather[['最低氣溫(℃)','最大陣風(m/s)','最大陣風風向(360degree)','最小相對溼度(%)','最高氣溫(℃)','氣溫(℃)','測站最低氣壓(hPa)','測站最高氣壓(hPa)','相對溼度(%)','風向(360degree)','測站氣壓(hPa)','降水量(mm)','風速(m/s)','year','month','day','date']]\n",
    "    weather=weather.drop(weather.index[[-1]])\n",
    "    column_list=list(weather.columns.values)\n",
    "    column_list.pop(-1)\n",
    "    for i in column_list:\n",
    "        for j in range(weather.shape[0]):\n",
    "            if str(weather[i][j]).replace(\".\", \"\", 1).isdigit()==False:\n",
    "                if j-1<0:\n",
    "                    weather[i][j]=0\n",
    "                else:\n",
    "                    weather[i][j]=weather[i][j-1]\n",
    "    weather.to_csv(\"changed\"+pl+\".csv\", encoding='utf_8_sig')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "place=[\"雲林\",\"嘉義\",\"彰化\",\"台南\",\"高雄\",\"屏東\",\"台中\",\"苗栗\",\"桃園\",\"台北\"]\n",
    "for i in place:\n",
    "    crop=pd.read_csv(\"甘藍-初秋.csv\")\n",
    "    weather=pd.read_csv(\"changed\"+i+\".csv\")\n",
    "    crop=crop.drop([\"Unnamed: 0\"], axis=1)\n",
    "    weather=weather.drop([\"Unnamed: 0\"], axis=1)\n",
    "    train=weather.merge(crop, on='date', how='left')\n",
    "    train=train.fillna(0)\n",
    "    train=train.drop([\"crop_name\"], axis=1)\n",
    "    train=train.drop([\"crop_num\"], axis=1)\n",
    "    train=train.drop([\"market_name\"], axis=1)\n",
    "    train=train.drop([\"market_num\"], axis=1)\n",
    "    train.to_csv(\"train\"+i+\".csv\", encoding='utf_8_sig')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
