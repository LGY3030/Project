{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(name):\n",
    "    train = pd.read_csv(name+\".csv\")\n",
    "    train=train.drop([\"date\"], axis=1)\n",
    "    train=train.drop([\"Unnamed: 0\"], axis=1)\n",
    "    return train\n",
    "\n",
    "def sta(train):\n",
    "    train=train.convert_objects(convert_numeric=True)\n",
    "    train= train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return train\n",
    "\n",
    "def buildTrain(train, pastDay, futureDay):\n",
    "    X_train, Y_train ,Z_train= [], [],[]\n",
    "    for i in range(train.shape[0]-futureDay-pastDay+1):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"high\"]))\n",
    "        Z_train.append(np.array(train.iloc[i+pastDay-1:i+pastDay+futureDay-1][\"high\"]))\n",
    "    return np.array(X_train), np.array(Y_train), np.array(Z_train)\n",
    "\n",
    "def shuffle(X,Y,Z):\n",
    "    np.random.seed()\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList],Z[randomList]\n",
    "\n",
    "def splitData(X,Y,Z,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    Z_val = Z[:int(Z.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val,Z_val\n",
    "\n",
    "def buildModel(train_x,train_y,bs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_length=train_x.shape[1],input_dim= train_x.shape[2],return_sequences=True))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.summary()\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_x,train_y, epochs=1000, batch_size=bs, validation_split=0.1, callbacks=[callback])\n",
    "    return model,[32,32,0,0,0]\n",
    "\n",
    "def predict(model,layer,val_x,val_y,val_z,x,y,name,num):\n",
    "    a=range(0,val_y.shape[0])\n",
    "    val_y=val_y.reshape(-1)\n",
    "    val_z=val_z.reshape(-1)\n",
    "    plt.plot(a,val_y)\n",
    "    b=[]\n",
    "    co=0\n",
    "    for i in range(0,val_x.shape[0]):\n",
    "        temp=val_x[i]\n",
    "        temp=temp.reshape(1,x,27)\n",
    "        z=int(model.predict(temp, verbose=0))\n",
    "        if val_y[i]>=val_z[i] and z>=val_z[i]:\n",
    "            co=co+1\n",
    "        if val_y[i]<val_z[i] and z<val_z[i]:\n",
    "            co=co+1\n",
    "        b.append(z)\n",
    "    b=np.array(b)\n",
    "    b=b.reshape(-1)\n",
    "    plt.plot(a,b)\n",
    "    acc=100*(co/val_x.shape[0])\n",
    "    plt.savefig('img/'+name+'('+str(num)+')'+str(layer[0])+'+'+str(layer[1])+'+'+str(layer[2])+'+'+str(layer[3])+'+'+str(layer[4])+'+'+'ac,'+str(acc)+\"%\"+'+'+'lb,'+str(x)+'+'+'bs,'+str(y)+'.jpg')\n",
    "    plt.clf()\n",
    "    return str(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:7: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  import sys\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:35: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(32, return_sequences=True, input_shape=(7, 22))`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 7, 32)             7040      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 15,393\n",
      "Trainable params: 15,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2257 samples, validate on 251 samples\n",
      "Epoch 1/1000\n",
      "2257/2257 [==============================] - 2s 701us/step - loss: 650.0646 - val_loss: 515.2853\n",
      "Epoch 2/1000\n",
      "2257/2257 [==============================] - 0s 186us/step - loss: 433.7960 - val_loss: 441.5553\n",
      "Epoch 3/1000\n",
      "2257/2257 [==============================] - 0s 184us/step - loss: 380.3240 - val_loss: 394.7469\n",
      "Epoch 4/1000\n",
      "2257/2257 [==============================] - 0s 185us/step - loss: 338.2632 - val_loss: 353.8075\n",
      "Epoch 5/1000\n",
      "2257/2257 [==============================] - 0s 185us/step - loss: 304.5997 - val_loss: 322.1633\n",
      "Epoch 6/1000\n",
      "2257/2257 [==============================] - 0s 185us/step - loss: 278.5126 - val_loss: 299.3251\n",
      "Epoch 7/1000\n",
      "2257/2257 [==============================] - 0s 185us/step - loss: 256.4705 - val_loss: 279.3952\n",
      "Epoch 8/1000\n",
      "2257/2257 [==============================] - 0s 204us/step - loss: 238.0042 - val_loss: 262.1923\n",
      "Epoch 9/1000\n",
      "2257/2257 [==============================] - 0s 186us/step - loss: 221.3999 - val_loss: 246.2381\n",
      "Epoch 10/1000\n",
      "2257/2257 [==============================] - 0s 184us/step - loss: 206.4434 - val_loss: 231.7397\n",
      "Epoch 11/1000\n",
      "  32/2257 [..............................] - ETA: 0s - loss: 181.1360"
     ]
    }
   ],
   "source": [
    "lookback=7\n",
    "batch_size=32\n",
    "col_name=[\"1\",\"2\",\"3\",\"4\",\"5\",\"acc\",\"lookback\",\"batch_size\",\"name\",\"num\"]\n",
    "place_name=[\"train+oil+weather+國定假日+拜拜日 雲林\",\"train+oil+weather+國定假日+拜拜日 嘉義\",\"train+oil+weather+國定假日+拜拜日 彰化\",\"train+oil+weather+國定假日+拜拜日 台南\",\"train+oil+weather+國定假日+拜拜日 高雄\",\"train+oil+weather+國定假日+拜拜日 屏東\",\"train+oil+weather+國定假日+拜拜日 台中\",\"train+oil+weather+國定假日+拜拜日 苗栗\",\"train+oil+weather+國定假日+拜拜日 桃園\",\"train+oil+weather+國定假日+拜拜日 台北\"]\n",
    "\n",
    "for i in place_name:\n",
    "    df=pd.DataFrame(columns=col_name)\n",
    "    data=[]\n",
    "    for j in range(30):\n",
    "        train=readData(i)\n",
    "        temp=train\n",
    "        train=sta(train)\n",
    "        train_x1,train_y1,train_z1=buildTrain(train,lookback,1)\n",
    "        train_x2,train_y2,train_z2=buildTrain(temp,lookback,1)\n",
    "        train_x,train_y,train_z=train_x1,train_y2,train_z2\n",
    "        train_x,train_y,train_z= shuffle(train_x,train_y,train_z)\n",
    "        train_x,train_y, val_x, val_y ,val_z= splitData(train_x,train_y,train_z, 0.05)\n",
    "        model,layer=buildModel(train_x,train_y,batch_size)\n",
    "        pre=predict(model,layer,val_x,val_y,val_z,lookback,batch_size,i,j)\n",
    "        data.append({\"1\":layer[0],\"2\":layer[1],\"3\":layer[2],\"4\":layer[3],\"5\":layer[4],\"acc\":pre,\"lookback\":lookback,\"batch_size\":batch_size,\"name\":i,\"num\":j})\n",
    "    df=pd.concat([pd.DataFrame(data), df], ignore_index=True,sort=True)\n",
    "    df.to_csv(i+'_data'+'(lookback  '+str(lookback)+')'+'(bs  '+str(batch_size)+')'+'.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
