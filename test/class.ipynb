{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(name):\n",
    "    train = pd.read_csv(name+\".csv\")\n",
    "    train=train.drop([\"date\"], axis=1)\n",
    "    train=train.drop([\"Unnamed: 0\"], axis=1)\n",
    "    return train\n",
    "\n",
    "def sta(train):\n",
    "    train=train.convert_objects(convert_numeric=True)\n",
    "    train= train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return train\n",
    "\n",
    "def buildTrain(train, pastDay, futureDay):\n",
    "    X_train, Y_train ,Z_train= [], [],[]\n",
    "    for i in range(train.shape[0]-futureDay-pastDay+1):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        a=np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"high\"])\n",
    "        b=np.array(train.iloc[i+pastDay-1:i+pastDay+futureDay-1][\"high\"])\n",
    "        if a>=b:\n",
    "            Y_train.append(1)\n",
    "        else:\n",
    "            Y_train.append(0)                                                       \n",
    "    return np.array(X_train), np.array(Y_train)\n",
    "\n",
    "def shuffle(X,Y):\n",
    "    np.random.seed()\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList]\n",
    "\n",
    "def splitData(X,Y,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def buildModel(train_x,train_y,bs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(32, input_length=train_x.shape[1],input_dim= train_x.shape[2],return_sequences=True))\n",
    "    model.add(LSTM(32))\n",
    "    model.add(Dense(1,kernel_initializer='uniform',activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_x,train_y, epochs=1000, batch_size=bs, validation_split=0.1, callbacks=[callback])\n",
    "    return model,[32,32,0,0,0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:39: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(32, input_shape=(7, 27), return_sequences=True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 7, 32)             7680      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 16,033\n",
      "Trainable params: 16,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2257 samples, validate on 251 samples\n",
      "Epoch 1/100\n",
      "2257/2257 [==============================] - 2s 828us/step - loss: 0.6924 - acc: 0.5224 - val_loss: 0.6929 - val_acc: 0.4861\n",
      "Epoch 2/100\n",
      "2257/2257 [==============================] - 0s 218us/step - loss: 0.6869 - acc: 0.5348 - val_loss: 0.6862 - val_acc: 0.5418\n",
      "Epoch 3/100\n",
      "2257/2257 [==============================] - 0s 202us/step - loss: 0.6685 - acc: 0.6083 - val_loss: 0.6626 - val_acc: 0.5857\n",
      "Epoch 4/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.6392 - acc: 0.6349 - val_loss: 0.6477 - val_acc: 0.6135\n",
      "Epoch 5/100\n",
      "2257/2257 [==============================] - 0s 202us/step - loss: 0.6258 - acc: 0.6402 - val_loss: 0.6308 - val_acc: 0.6175\n",
      "Epoch 6/100\n",
      "2257/2257 [==============================] - 0s 207us/step - loss: 0.6174 - acc: 0.6429 - val_loss: 0.6249 - val_acc: 0.6175\n",
      "Epoch 7/100\n",
      "2257/2257 [==============================] - 0s 203us/step - loss: 0.6074 - acc: 0.6438 - val_loss: 0.6067 - val_acc: 0.6135\n",
      "Epoch 8/100\n",
      "2257/2257 [==============================] - 0s 200us/step - loss: 0.5860 - acc: 0.6460 - val_loss: 0.5721 - val_acc: 0.6215\n",
      "Epoch 9/100\n",
      "2257/2257 [==============================] - 0s 191us/step - loss: 0.5560 - acc: 0.6504 - val_loss: 0.5426 - val_acc: 0.6892\n",
      "Epoch 10/100\n",
      "2257/2257 [==============================] - 0s 218us/step - loss: 0.5387 - acc: 0.6695 - val_loss: 0.5219 - val_acc: 0.6892\n",
      "Epoch 11/100\n",
      "2257/2257 [==============================] - 1s 224us/step - loss: 0.5317 - acc: 0.6792 - val_loss: 0.5251 - val_acc: 0.6972\n",
      "Epoch 12/100\n",
      "2257/2257 [==============================] - 0s 220us/step - loss: 0.5271 - acc: 0.6735 - val_loss: 0.4982 - val_acc: 0.7131\n",
      "Epoch 13/100\n",
      "2257/2257 [==============================] - 0s 212us/step - loss: 0.5222 - acc: 0.6859 - val_loss: 0.5229 - val_acc: 0.7052\n",
      "Epoch 14/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.5149 - acc: 0.6783 - val_loss: 0.4959 - val_acc: 0.7012\n",
      "Epoch 15/100\n",
      "2257/2257 [==============================] - 0s 200us/step - loss: 0.5110 - acc: 0.6823 - val_loss: 0.4908 - val_acc: 0.7171\n",
      "Epoch 16/100\n",
      "2257/2257 [==============================] - 0s 201us/step - loss: 0.5070 - acc: 0.6912 - val_loss: 0.4971 - val_acc: 0.7291\n",
      "Epoch 17/100\n",
      "2257/2257 [==============================] - 0s 190us/step - loss: 0.5031 - acc: 0.6916 - val_loss: 0.5008 - val_acc: 0.7131\n",
      "Epoch 18/100\n",
      "2257/2257 [==============================] - 0s 190us/step - loss: 0.4976 - acc: 0.7000 - val_loss: 0.4905 - val_acc: 0.7052\n",
      "Epoch 19/100\n",
      "2257/2257 [==============================] - 0s 204us/step - loss: 0.4954 - acc: 0.7036 - val_loss: 0.4924 - val_acc: 0.7131\n",
      "Epoch 20/100\n",
      "2257/2257 [==============================] - 0s 204us/step - loss: 0.4917 - acc: 0.7045 - val_loss: 0.5204 - val_acc: 0.6972\n",
      "Epoch 21/100\n",
      "2257/2257 [==============================] - 0s 203us/step - loss: 0.4881 - acc: 0.7098 - val_loss: 0.4969 - val_acc: 0.7052\n",
      "Epoch 22/100\n",
      "2257/2257 [==============================] - 0s 201us/step - loss: 0.4850 - acc: 0.7133 - val_loss: 0.5123 - val_acc: 0.7052\n",
      "Epoch 23/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.4805 - acc: 0.7080 - val_loss: 0.5128 - val_acc: 0.7211\n",
      "Epoch 24/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.4736 - acc: 0.7213 - val_loss: 0.4858 - val_acc: 0.7251\n",
      "Epoch 25/100\n",
      "2257/2257 [==============================] - 0s 208us/step - loss: 0.4733 - acc: 0.7182 - val_loss: 0.4885 - val_acc: 0.7052\n",
      "Epoch 26/100\n",
      "2257/2257 [==============================] - 0s 183us/step - loss: 0.4684 - acc: 0.7244 - val_loss: 0.4969 - val_acc: 0.6972\n",
      "Epoch 27/100\n",
      "2257/2257 [==============================] - 0s 188us/step - loss: 0.4681 - acc: 0.7253 - val_loss: 0.4859 - val_acc: 0.7131\n",
      "Epoch 28/100\n",
      "2257/2257 [==============================] - 0s 200us/step - loss: 0.4633 - acc: 0.7342 - val_loss: 0.5097 - val_acc: 0.6892\n",
      "Epoch 29/100\n",
      "2257/2257 [==============================] - 0s 203us/step - loss: 0.4594 - acc: 0.7412 - val_loss: 0.4893 - val_acc: 0.7131\n",
      "Epoch 30/100\n",
      "2257/2257 [==============================] - 0s 193us/step - loss: 0.4586 - acc: 0.7381 - val_loss: 0.4995 - val_acc: 0.7052\n",
      "Epoch 31/100\n",
      "2257/2257 [==============================] - 0s 188us/step - loss: 0.4497 - acc: 0.7466 - val_loss: 0.5178 - val_acc: 0.7012\n",
      "Epoch 32/100\n",
      "2257/2257 [==============================] - 0s 192us/step - loss: 0.4504 - acc: 0.7439 - val_loss: 0.5485 - val_acc: 0.6773\n",
      "Epoch 33/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.4488 - acc: 0.7355 - val_loss: 0.4956 - val_acc: 0.7012\n",
      "Epoch 34/100\n",
      "2257/2257 [==============================] - 0s 209us/step - loss: 0.4448 - acc: 0.7514 - val_loss: 0.4947 - val_acc: 0.7251\n",
      "Epoch 35/100\n",
      "2257/2257 [==============================] - 0s 196us/step - loss: 0.4437 - acc: 0.7532 - val_loss: 0.5033 - val_acc: 0.7052\n",
      "Epoch 36/100\n",
      "2257/2257 [==============================] - 0s 197us/step - loss: 0.4360 - acc: 0.7585 - val_loss: 0.4903 - val_acc: 0.7171\n",
      "Epoch 37/100\n",
      "2257/2257 [==============================] - 0s 206us/step - loss: 0.4342 - acc: 0.7532 - val_loss: 0.5308 - val_acc: 0.7012\n",
      "Epoch 38/100\n",
      "2257/2257 [==============================] - 0s 218us/step - loss: 0.4336 - acc: 0.7537 - val_loss: 0.5117 - val_acc: 0.7171\n",
      "Epoch 39/100\n",
      "2257/2257 [==============================] - 1s 224us/step - loss: 0.4321 - acc: 0.7621 - val_loss: 0.4983 - val_acc: 0.7052\n",
      "Epoch 40/100\n",
      "2257/2257 [==============================] - 0s 221us/step - loss: 0.4272 - acc: 0.7674 - val_loss: 0.5395 - val_acc: 0.6892\n",
      "Epoch 41/100\n",
      "2257/2257 [==============================] - 0s 218us/step - loss: 0.4202 - acc: 0.7727 - val_loss: 0.5434 - val_acc: 0.7092\n",
      "Epoch 42/100\n",
      "2257/2257 [==============================] - 1s 230us/step - loss: 0.4203 - acc: 0.7669 - val_loss: 0.5204 - val_acc: 0.7131\n",
      "Epoch 43/100\n",
      "2257/2257 [==============================] - 1s 226us/step - loss: 0.4150 - acc: 0.7754 - val_loss: 0.5135 - val_acc: 0.7171\n",
      "Epoch 44/100\n",
      "2257/2257 [==============================] - 1s 222us/step - loss: 0.4123 - acc: 0.7732 - val_loss: 0.4941 - val_acc: 0.7291\n",
      "Epoch 45/100\n",
      "2257/2257 [==============================] - 0s 212us/step - loss: 0.4062 - acc: 0.7811 - val_loss: 0.5260 - val_acc: 0.7171\n",
      "Epoch 46/100\n",
      "2257/2257 [==============================] - 1s 225us/step - loss: 0.4040 - acc: 0.7816 - val_loss: 0.5340 - val_acc: 0.7211\n",
      "Epoch 47/100\n",
      "2257/2257 [==============================] - 1s 235us/step - loss: 0.3985 - acc: 0.7838 - val_loss: 0.5477 - val_acc: 0.7171\n",
      "Epoch 48/100\n",
      "2257/2257 [==============================] - 1s 226us/step - loss: 0.3939 - acc: 0.7909 - val_loss: 0.5324 - val_acc: 0.7291\n",
      "Epoch 49/100\n",
      "2257/2257 [==============================] - 1s 235us/step - loss: 0.3859 - acc: 0.8028 - val_loss: 0.5597 - val_acc: 0.7410\n",
      "Epoch 50/100\n",
      "2257/2257 [==============================] - 0s 221us/step - loss: 0.3851 - acc: 0.7975 - val_loss: 0.5515 - val_acc: 0.7131\n",
      "Epoch 51/100\n",
      "2257/2257 [==============================] - 1s 229us/step - loss: 0.3774 - acc: 0.8042 - val_loss: 0.5369 - val_acc: 0.7211\n",
      "Epoch 52/100\n",
      "2257/2257 [==============================] - 1s 239us/step - loss: 0.3736 - acc: 0.8073 - val_loss: 0.5459 - val_acc: 0.7131\n",
      "Epoch 53/100\n",
      "2257/2257 [==============================] - 1s 227us/step - loss: 0.3650 - acc: 0.8135 - val_loss: 0.5736 - val_acc: 0.7092\n",
      "Epoch 54/100\n",
      "2257/2257 [==============================] - 0s 213us/step - loss: 0.3609 - acc: 0.8210 - val_loss: 0.5755 - val_acc: 0.7131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.3538 - acc: 0.8259 - val_loss: 0.5654 - val_acc: 0.7131\n",
      "Epoch 56/100\n",
      "2257/2257 [==============================] - 1s 224us/step - loss: 0.3511 - acc: 0.8268 - val_loss: 0.6065 - val_acc: 0.6892\n",
      "Epoch 57/100\n",
      "2257/2257 [==============================] - 1s 224us/step - loss: 0.3419 - acc: 0.8352 - val_loss: 0.5711 - val_acc: 0.7291\n",
      "Epoch 58/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.3372 - acc: 0.8418 - val_loss: 0.5951 - val_acc: 0.7211\n",
      "Epoch 59/100\n",
      "2257/2257 [==============================] - 0s 205us/step - loss: 0.3337 - acc: 0.8374 - val_loss: 0.6488 - val_acc: 0.7131\n",
      "Epoch 60/100\n",
      "2257/2257 [==============================] - 0s 216us/step - loss: 0.3235 - acc: 0.8480 - val_loss: 0.6087 - val_acc: 0.7052\n",
      "Epoch 61/100\n",
      "2257/2257 [==============================] - 1s 234us/step - loss: 0.3163 - acc: 0.8525 - val_loss: 0.6690 - val_acc: 0.7052\n",
      "Epoch 62/100\n",
      "2257/2257 [==============================] - 1s 224us/step - loss: 0.3170 - acc: 0.8476 - val_loss: 0.6583 - val_acc: 0.7171\n",
      "Epoch 63/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.3039 - acc: 0.8564 - val_loss: 0.6325 - val_acc: 0.7052\n",
      "Epoch 64/100\n",
      "2257/2257 [==============================] - 0s 205us/step - loss: 0.3023 - acc: 0.8626 - val_loss: 0.6355 - val_acc: 0.7092\n",
      "Epoch 65/100\n",
      "2257/2257 [==============================] - 1s 233us/step - loss: 0.3007 - acc: 0.8516 - val_loss: 0.6323 - val_acc: 0.7131\n",
      "Epoch 66/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.2848 - acc: 0.8706 - val_loss: 0.6939 - val_acc: 0.7131\n",
      "Epoch 67/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.2783 - acc: 0.8751 - val_loss: 0.7451 - val_acc: 0.6972\n",
      "Epoch 68/100\n",
      "2257/2257 [==============================] - 0s 195us/step - loss: 0.2782 - acc: 0.8808 - val_loss: 0.6846 - val_acc: 0.7092\n",
      "Epoch 69/100\n",
      "2257/2257 [==============================] - 0s 203us/step - loss: 0.2695 - acc: 0.8839 - val_loss: 0.7070 - val_acc: 0.7211\n",
      "Epoch 70/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.2625 - acc: 0.8910 - val_loss: 0.7304 - val_acc: 0.7171\n",
      "Epoch 71/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.2555 - acc: 0.8883 - val_loss: 0.7434 - val_acc: 0.7012\n",
      "Epoch 72/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.2573 - acc: 0.8941 - val_loss: 0.7001 - val_acc: 0.7251\n",
      "Epoch 73/100\n",
      "2257/2257 [==============================] - 1s 227us/step - loss: 0.2437 - acc: 0.8941 - val_loss: 0.7588 - val_acc: 0.7131\n",
      "Epoch 74/100\n",
      "2257/2257 [==============================] - 1s 229us/step - loss: 0.2359 - acc: 0.9021 - val_loss: 0.7634 - val_acc: 0.7211\n",
      "Epoch 75/100\n",
      "2257/2257 [==============================] - 1s 230us/step - loss: 0.2291 - acc: 0.9070 - val_loss: 0.7657 - val_acc: 0.7131\n",
      "Epoch 76/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.2212 - acc: 0.9105 - val_loss: 0.7984 - val_acc: 0.7251\n",
      "Epoch 77/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.2165 - acc: 0.9109 - val_loss: 0.8111 - val_acc: 0.7092\n",
      "Epoch 78/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.2153 - acc: 0.9136 - val_loss: 0.7904 - val_acc: 0.7211\n",
      "Epoch 79/100\n",
      "2257/2257 [==============================] - 1s 235us/step - loss: 0.2013 - acc: 0.9154 - val_loss: 0.8100 - val_acc: 0.7171\n",
      "Epoch 80/100\n",
      "2257/2257 [==============================] - 1s 246us/step - loss: 0.2025 - acc: 0.9180 - val_loss: 0.8486 - val_acc: 0.7052\n",
      "Epoch 81/100\n",
      "2257/2257 [==============================] - 0s 207us/step - loss: 0.1883 - acc: 0.9296 - val_loss: 0.8793 - val_acc: 0.7251\n",
      "Epoch 82/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.1915 - acc: 0.9260 - val_loss: 0.8433 - val_acc: 0.7131\n",
      "Epoch 83/100\n",
      "2257/2257 [==============================] - 1s 241us/step - loss: 0.1805 - acc: 0.9309 - val_loss: 0.8616 - val_acc: 0.7291\n",
      "Epoch 84/100\n",
      "2257/2257 [==============================] - 1s 230us/step - loss: 0.1694 - acc: 0.9380 - val_loss: 0.9153 - val_acc: 0.7131\n",
      "Epoch 85/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.1593 - acc: 0.9464 - val_loss: 0.8873 - val_acc: 0.7211\n",
      "Epoch 86/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.1564 - acc: 0.9411 - val_loss: 0.9349 - val_acc: 0.7131\n",
      "Epoch 87/100\n",
      "2257/2257 [==============================] - 0s 221us/step - loss: 0.1534 - acc: 0.9442 - val_loss: 0.8980 - val_acc: 0.7450\n",
      "Epoch 88/100\n",
      "2257/2257 [==============================] - 1s 234us/step - loss: 0.1459 - acc: 0.9437 - val_loss: 0.9654 - val_acc: 0.7131\n",
      "Epoch 89/100\n",
      "2257/2257 [==============================] - 1s 224us/step - loss: 0.1446 - acc: 0.9473 - val_loss: 0.9305 - val_acc: 0.7251\n",
      "Epoch 90/100\n",
      "2257/2257 [==============================] - 1s 250us/step - loss: 0.1405 - acc: 0.9557 - val_loss: 1.0273 - val_acc: 0.7052\n",
      "Epoch 91/100\n",
      "2257/2257 [==============================] - 0s 216us/step - loss: 0.1344 - acc: 0.9517 - val_loss: 1.0040 - val_acc: 0.7251\n",
      "Epoch 92/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.1291 - acc: 0.9513 - val_loss: 0.9907 - val_acc: 0.7251\n",
      "Epoch 93/100\n",
      "2257/2257 [==============================] - 1s 232us/step - loss: 0.1179 - acc: 0.9619 - val_loss: 1.0485 - val_acc: 0.7331\n",
      "Epoch 94/100\n",
      "2257/2257 [==============================] - 1s 227us/step - loss: 0.1104 - acc: 0.9672 - val_loss: 1.0355 - val_acc: 0.7410\n",
      "Epoch 95/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.1050 - acc: 0.9672 - val_loss: 1.0275 - val_acc: 0.7291\n",
      "Epoch 96/100\n",
      "2257/2257 [==============================] - 0s 207us/step - loss: 0.0996 - acc: 0.9681 - val_loss: 1.0678 - val_acc: 0.7331\n",
      "Epoch 97/100\n",
      "2257/2257 [==============================] - 1s 234us/step - loss: 0.0955 - acc: 0.9725 - val_loss: 1.1073 - val_acc: 0.7331\n",
      "Epoch 98/100\n",
      "2257/2257 [==============================] - 1s 225us/step - loss: 0.0942 - acc: 0.9725 - val_loss: 1.1043 - val_acc: 0.7291\n",
      "Epoch 99/100\n",
      "2257/2257 [==============================] - 1s 238us/step - loss: 0.0851 - acc: 0.9752 - val_loss: 1.0871 - val_acc: 0.7410\n",
      "Epoch 100/100\n",
      "2257/2257 [==============================] - 0s 217us/step - loss: 0.0785 - acc: 0.9783 - val_loss: 1.1103 - val_acc: 0.7291\n",
      "0.610687023128262\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 7, 32)             7680      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 16,033\n",
      "Trainable params: 16,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2257 samples, validate on 251 samples\n",
      "Epoch 1/100\n",
      "2257/2257 [==============================] - 2s 836us/step - loss: 0.6928 - acc: 0.5140 - val_loss: 0.6917 - val_acc: 0.5418\n",
      "Epoch 2/100\n",
      "2257/2257 [==============================] - 1s 240us/step - loss: 0.6896 - acc: 0.5312 - val_loss: 0.6849 - val_acc: 0.5857\n",
      "Epoch 3/100\n",
      "2257/2257 [==============================] - 1s 222us/step - loss: 0.6771 - acc: 0.5755 - val_loss: 0.6672 - val_acc: 0.5936\n",
      "Epoch 4/100\n",
      "2257/2257 [==============================] - 0s 200us/step - loss: 0.6545 - acc: 0.6083 - val_loss: 0.6224 - val_acc: 0.6534\n",
      "Epoch 5/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.6332 - acc: 0.6234 - val_loss: 0.5978 - val_acc: 0.6653\n",
      "Epoch 6/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.6228 - acc: 0.6309 - val_loss: 0.5866 - val_acc: 0.6653\n",
      "Epoch 7/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.6074 - acc: 0.6300 - val_loss: 0.5573 - val_acc: 0.6574\n",
      "Epoch 8/100\n",
      "2257/2257 [==============================] - 0s 190us/step - loss: 0.5738 - acc: 0.6300 - val_loss: 0.5090 - val_acc: 0.7131\n",
      "Epoch 9/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.5512 - acc: 0.6575 - val_loss: 0.5031 - val_acc: 0.7052\n",
      "Epoch 10/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.5402 - acc: 0.6642 - val_loss: 0.4894 - val_acc: 0.7251\n",
      "Epoch 11/100\n",
      "2257/2257 [==============================] - 0s 208us/step - loss: 0.5334 - acc: 0.6642 - val_loss: 0.4761 - val_acc: 0.7291\n",
      "Epoch 12/100\n",
      "2257/2257 [==============================] - 0s 191us/step - loss: 0.5256 - acc: 0.6726 - val_loss: 0.4748 - val_acc: 0.7291\n",
      "Epoch 13/100\n",
      "2257/2257 [==============================] - 0s 190us/step - loss: 0.5235 - acc: 0.6770 - val_loss: 0.4740 - val_acc: 0.7131\n",
      "Epoch 14/100\n",
      "2257/2257 [==============================] - 0s 212us/step - loss: 0.5149 - acc: 0.6863 - val_loss: 0.4626 - val_acc: 0.7410\n",
      "Epoch 15/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.5125 - acc: 0.6921 - val_loss: 0.4644 - val_acc: 0.7092\n",
      "Epoch 16/100\n",
      "2257/2257 [==============================] - 0s 194us/step - loss: 0.5089 - acc: 0.6956 - val_loss: 0.4680 - val_acc: 0.6932\n",
      "Epoch 17/100\n",
      "2257/2257 [==============================] - 0s 195us/step - loss: 0.5005 - acc: 0.6983 - val_loss: 0.4626 - val_acc: 0.7291\n",
      "Epoch 18/100\n",
      "2257/2257 [==============================] - 0s 209us/step - loss: 0.4979 - acc: 0.6983 - val_loss: 0.4587 - val_acc: 0.7131\n",
      "Epoch 19/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.4934 - acc: 0.7071 - val_loss: 0.4597 - val_acc: 0.7052\n",
      "Epoch 20/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.4908 - acc: 0.6996 - val_loss: 0.4571 - val_acc: 0.7171\n",
      "Epoch 21/100\n",
      "2257/2257 [==============================] - 0s 198us/step - loss: 0.4865 - acc: 0.7125 - val_loss: 0.4527 - val_acc: 0.7171\n",
      "Epoch 22/100\n",
      "2257/2257 [==============================] - 0s 193us/step - loss: 0.4836 - acc: 0.7116 - val_loss: 0.4665 - val_acc: 0.7092\n",
      "Epoch 23/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.4802 - acc: 0.7147 - val_loss: 0.4542 - val_acc: 0.7211\n",
      "Epoch 24/100\n",
      "2257/2257 [==============================] - 0s 214us/step - loss: 0.4753 - acc: 0.7249 - val_loss: 0.4827 - val_acc: 0.7012\n",
      "Epoch 25/100\n",
      "2257/2257 [==============================] - 0s 194us/step - loss: 0.4739 - acc: 0.7244 - val_loss: 0.4564 - val_acc: 0.7052\n",
      "Epoch 26/100\n",
      "2257/2257 [==============================] - 0s 193us/step - loss: 0.4695 - acc: 0.7288 - val_loss: 0.4694 - val_acc: 0.7171\n",
      "Epoch 27/100\n",
      "2257/2257 [==============================] - 0s 208us/step - loss: 0.4631 - acc: 0.7346 - val_loss: 0.4672 - val_acc: 0.7171\n",
      "Epoch 28/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.4568 - acc: 0.7457 - val_loss: 0.4669 - val_acc: 0.7410\n",
      "Epoch 29/100\n",
      "2257/2257 [==============================] - 0s 203us/step - loss: 0.4554 - acc: 0.7444 - val_loss: 0.4839 - val_acc: 0.7251\n",
      "Epoch 30/100\n",
      "2257/2257 [==============================] - 0s 193us/step - loss: 0.4536 - acc: 0.7457 - val_loss: 0.4680 - val_acc: 0.7171\n",
      "Epoch 31/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.4460 - acc: 0.7523 - val_loss: 0.4769 - val_acc: 0.7251\n",
      "Epoch 32/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.4384 - acc: 0.7709 - val_loss: 0.4914 - val_acc: 0.7211\n",
      "Epoch 33/100\n",
      "2257/2257 [==============================] - 0s 213us/step - loss: 0.4374 - acc: 0.7652 - val_loss: 0.4866 - val_acc: 0.7211\n",
      "Epoch 34/100\n",
      "2257/2257 [==============================] - 0s 196us/step - loss: 0.4342 - acc: 0.7661 - val_loss: 0.5054 - val_acc: 0.7331\n",
      "Epoch 35/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.4295 - acc: 0.7767 - val_loss: 0.5232 - val_acc: 0.7092\n",
      "Epoch 36/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.4199 - acc: 0.7802 - val_loss: 0.4834 - val_acc: 0.7171\n",
      "Epoch 37/100\n",
      "2257/2257 [==============================] - 1s 227us/step - loss: 0.4178 - acc: 0.7856 - val_loss: 0.4888 - val_acc: 0.7171\n",
      "Epoch 38/100\n",
      "2257/2257 [==============================] - 1s 233us/step - loss: 0.4112 - acc: 0.7811 - val_loss: 0.5501 - val_acc: 0.7171\n",
      "Epoch 39/100\n",
      "2257/2257 [==============================] - 0s 217us/step - loss: 0.4124 - acc: 0.7829 - val_loss: 0.5040 - val_acc: 0.7092\n",
      "Epoch 40/100\n",
      "2257/2257 [==============================] - 0s 208us/step - loss: 0.4016 - acc: 0.7913 - val_loss: 0.5080 - val_acc: 0.7131\n",
      "Epoch 41/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.3948 - acc: 0.8037 - val_loss: 0.5107 - val_acc: 0.7211\n",
      "Epoch 42/100\n",
      "2257/2257 [==============================] - 0s 218us/step - loss: 0.3980 - acc: 0.7944 - val_loss: 0.5010 - val_acc: 0.7371\n",
      "Epoch 43/100\n",
      "2257/2257 [==============================] - 0s 202us/step - loss: 0.3872 - acc: 0.8095 - val_loss: 0.5408 - val_acc: 0.7251\n",
      "Epoch 44/100\n",
      "2257/2257 [==============================] - 0s 193us/step - loss: 0.3786 - acc: 0.8108 - val_loss: 0.5331 - val_acc: 0.6972\n",
      "Epoch 45/100\n",
      "2257/2257 [==============================] - 0s 205us/step - loss: 0.3744 - acc: 0.8126 - val_loss: 0.5473 - val_acc: 0.7092\n",
      "Epoch 46/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.3715 - acc: 0.8139 - val_loss: 0.5605 - val_acc: 0.6972\n",
      "Epoch 47/100\n",
      "2257/2257 [==============================] - 0s 211us/step - loss: 0.3642 - acc: 0.8214 - val_loss: 0.5561 - val_acc: 0.7092\n",
      "Epoch 48/100\n",
      "2257/2257 [==============================] - 0s 195us/step - loss: 0.3568 - acc: 0.8281 - val_loss: 0.5689 - val_acc: 0.6892\n",
      "Epoch 49/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.3524 - acc: 0.8254 - val_loss: 0.5702 - val_acc: 0.6932\n",
      "Epoch 50/100\n",
      "2257/2257 [==============================] - 0s 217us/step - loss: 0.3453 - acc: 0.8330 - val_loss: 0.5900 - val_acc: 0.6892\n",
      "Epoch 51/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.3421 - acc: 0.8352 - val_loss: 0.5742 - val_acc: 0.7171\n",
      "Epoch 52/100\n",
      "2257/2257 [==============================] - 0s 205us/step - loss: 0.3316 - acc: 0.8432 - val_loss: 0.5945 - val_acc: 0.7012\n",
      "Epoch 53/100\n",
      "2257/2257 [==============================] - 0s 205us/step - loss: 0.3273 - acc: 0.8445 - val_loss: 0.5984 - val_acc: 0.7052\n",
      "Epoch 54/100\n",
      "2257/2257 [==============================] - 0s 217us/step - loss: 0.3260 - acc: 0.8356 - val_loss: 0.6279 - val_acc: 0.7052\n",
      "Epoch 55/100\n",
      "2257/2257 [==============================] - 0s 217us/step - loss: 0.3150 - acc: 0.8542 - val_loss: 0.6233 - val_acc: 0.7052\n",
      "Epoch 56/100\n",
      "2257/2257 [==============================] - 0s 216us/step - loss: 0.3135 - acc: 0.8587 - val_loss: 0.6170 - val_acc: 0.6972\n",
      "Epoch 57/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.2998 - acc: 0.8631 - val_loss: 0.6301 - val_acc: 0.7052\n",
      "Epoch 58/100\n",
      "2257/2257 [==============================] - 0s 210us/step - loss: 0.2993 - acc: 0.8680 - val_loss: 0.6225 - val_acc: 0.7092\n",
      "Epoch 59/100\n",
      "2257/2257 [==============================] - 0s 219us/step - loss: 0.2900 - acc: 0.8737 - val_loss: 0.6431 - val_acc: 0.7131\n",
      "Epoch 60/100\n",
      "2257/2257 [==============================] - 1s 223us/step - loss: 0.2790 - acc: 0.8751 - val_loss: 0.6560 - val_acc: 0.7251\n",
      "Epoch 61/100\n",
      "2257/2257 [==============================] - 0s 212us/step - loss: 0.2722 - acc: 0.8773 - val_loss: 0.6915 - val_acc: 0.7211\n",
      "Epoch 62/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.2721 - acc: 0.8777 - val_loss: 0.6759 - val_acc: 0.7052\n",
      "Epoch 63/100\n",
      "2257/2257 [==============================] - 0s 208us/step - loss: 0.2687 - acc: 0.8795 - val_loss: 0.6980 - val_acc: 0.7211\n",
      "Epoch 64/100\n",
      "2257/2257 [==============================] - 1s 251us/step - loss: 0.2589 - acc: 0.8839 - val_loss: 0.7334 - val_acc: 0.6972\n",
      "Epoch 65/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.2493 - acc: 0.8937 - val_loss: 0.7388 - val_acc: 0.7012\n",
      "Epoch 66/100\n",
      "2257/2257 [==============================] - 0s 219us/step - loss: 0.2428 - acc: 0.8963 - val_loss: 0.7646 - val_acc: 0.7012\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2257/2257 [==============================] - 0s 203us/step - loss: 0.2318 - acc: 0.9025 - val_loss: 0.7700 - val_acc: 0.7211\n",
      "Epoch 68/100\n",
      "2257/2257 [==============================] - 0s 219us/step - loss: 0.2255 - acc: 0.9034 - val_loss: 0.7794 - val_acc: 0.6972\n",
      "Epoch 69/100\n",
      "2257/2257 [==============================] - 0s 216us/step - loss: 0.2172 - acc: 0.9105 - val_loss: 0.7994 - val_acc: 0.6932\n",
      "Epoch 70/100\n",
      "2257/2257 [==============================] - 0s 199us/step - loss: 0.2126 - acc: 0.9123 - val_loss: 0.8242 - val_acc: 0.6972\n",
      "Epoch 71/100\n",
      "2257/2257 [==============================] - 0s 217us/step - loss: 0.2078 - acc: 0.9154 - val_loss: 0.9063 - val_acc: 0.6892\n",
      "Epoch 72/100\n",
      "2257/2257 [==============================] - 0s 218us/step - loss: 0.1979 - acc: 0.9158 - val_loss: 0.8509 - val_acc: 0.7012\n",
      "Epoch 73/100\n",
      "2257/2257 [==============================] - 0s 218us/step - loss: 0.1889 - acc: 0.9220 - val_loss: 0.8547 - val_acc: 0.7092\n",
      "Epoch 74/100\n",
      "2257/2257 [==============================] - 0s 215us/step - loss: 0.1832 - acc: 0.9304 - val_loss: 0.9222 - val_acc: 0.6972\n",
      "Epoch 75/100\n",
      "2257/2257 [==============================] - 0s 206us/step - loss: 0.1694 - acc: 0.9362 - val_loss: 0.9538 - val_acc: 0.7052\n",
      "Epoch 76/100\n",
      "2257/2257 [==============================] - 1s 237us/step - loss: 0.1680 - acc: 0.9371 - val_loss: 0.9529 - val_acc: 0.7131\n",
      "Epoch 77/100\n",
      "2257/2257 [==============================] - 1s 229us/step - loss: 0.1608 - acc: 0.9362 - val_loss: 0.9351 - val_acc: 0.7171\n",
      "Epoch 78/100\n",
      " 544/2257 [======>.......................] - ETA: 0s - loss: 0.1390 - acc: 0.9522"
     ]
    }
   ],
   "source": [
    "lookback=7\n",
    "batch_size=32\n",
    "col_name=[\"1\",\"2\",\"3\",\"4\",\"5\",\"acc\",\"lookback\",\"batch_size\",\"name\",\"num\"]\n",
    "place_name=[\"train+oil+weather+國定假日+拜拜日 雲林\",\"train+oil+weather+國定假日+拜拜日 嘉義\",\"train+oil+weather+國定假日+拜拜日 彰化\",\"train+oil+weather+國定假日+拜拜日 台南\",\"train+oil+weather+國定假日+拜拜日 高雄\",\"train+oil+weather+國定假日+拜拜日 屏東\",\"train+oil+weather+國定假日+拜拜日 台中\",\"train+oil+weather+國定假日+拜拜日 苗栗\",\"train+oil+weather+國定假日+拜拜日 桃園\",\"train+oil+weather+國定假日+拜拜日 台北\"]\n",
    "for i in place_name:\n",
    "    df=pd.DataFrame(columns=col_name)\n",
    "    data=[]\n",
    "    for j in range(5):\n",
    "        train=readData(i)\n",
    "        temp=train\n",
    "        train=sta(train)\n",
    "        train_x1,train_y1=buildTrain(train,lookback,1)\n",
    "        train_x2,train_y2=buildTrain(temp,lookback,1)\n",
    "        train_x,train_y=train_x1,train_y2\n",
    "        train_x,train_y= shuffle(train_x,train_y)\n",
    "        train_x,train_y, val_x, val_y= splitData(train_x,train_y, 0.05)\n",
    "        model,layer=buildModel(train_x,train_y,batch_size)\n",
    "        pre=model.evaluate(val_x,val_y,verbose=0)\n",
    "        data.append({\"1\":layer[0],\"2\":layer[1],\"3\":layer[2],\"4\":layer[3],\"5\":layer[4],\"acc\":pre[1]*100,\"lookback\":lookback,\"batch_size\":batch_size,\"name\":i,\"num\":j})\n",
    "        \n",
    "    df=pd.concat([pd.DataFrame(data), df], ignore_index=True,sort=True)\n",
    "    df.to_csv('class'+i+'_data'+'(lookback  '+str(lookback)+')'+'(bs  '+str(batch_size)+')'+'.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
