{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,LSTM,Dropout,Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(name):\n",
    "    train = pd.read_csv(\"甘藍-初秋.csv\")\n",
    "    train=train.drop([\"Unnamed: 0\"], axis=1)\n",
    "    train=train.drop([\"crop_name\"], axis=1)\n",
    "    train=train.drop([\"crop_num\"], axis=1)\n",
    "    train=train.drop([\"market_name\"], axis=1)\n",
    "    train=train.drop([\"market_num\"], axis=1)\n",
    "    \n",
    "\n",
    "    weather=pd.read_csv(name+\".csv\")\n",
    "    weather=weather[['測站氣壓(hPa)','降水量(mm)','風速(m/s)','year','month','day']]\n",
    "    \n",
    "\n",
    "    return train,weather\n",
    "\n",
    "def concatData(train,weather):\n",
    "    a=0\n",
    "    b=0\n",
    "    c=weather.shape[0]\n",
    "    d=0\n",
    "    for i in range(0,train.shape[0]):\n",
    "        for j in range(a,c-d):\n",
    "            if all([train[\"year\"][i]==weather[\"year\"][j] , train[\"month\"][i]==weather[\"month\"][j] , train[\"day\"][i]==weather[\"day\"][j]]):\n",
    "                weather=weather.drop(weather.index[a:b+a])\n",
    "                weather.reset_index(inplace=True)\n",
    "                weather=weather.drop([\"index\"], axis=1)\n",
    "                a=a+1\n",
    "                b=0\n",
    "                break\n",
    "            else:\n",
    "                b=b+1\n",
    "                d=d+1\n",
    "    weather=weather.drop(weather.index[train.shape[0]:])\n",
    "    weather.reset_index(inplace=True)\n",
    "    weather=weather.drop([\"index\"], axis=1)\n",
    "    train=pd.concat([train,weather],axis=1)\n",
    "    return train\n",
    "\n",
    "def sta(train):\n",
    "    train=train.convert_objects(convert_numeric=True)\n",
    "    train= train.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))\n",
    "    return train\n",
    "\n",
    "def buildTrain(train, pastDay, futureDay):\n",
    "    X_train, Y_train ,Z_train= [], [],[]\n",
    "    for i in range(train.shape[0]-futureDay-pastDay+1):\n",
    "        X_train.append(np.array(train.iloc[i:i+pastDay]))\n",
    "        Y_train.append(np.array(train.iloc[i+pastDay:i+pastDay+futureDay][\"high\"]))\n",
    "        Z_train.append(np.array(train.iloc[i+pastDay-1:i+pastDay+futureDay-1][\"high\"]))\n",
    "    return np.array(X_train), np.array(Y_train), np.array(Z_train)\n",
    "\n",
    "def shuffle(X,Y,Z):\n",
    "    np.random.seed()\n",
    "    randomList = np.arange(X.shape[0])\n",
    "    np.random.shuffle(randomList)\n",
    "    return X[randomList], Y[randomList],Z[randomList]\n",
    "\n",
    "def splitData(X,Y,Z,rate):\n",
    "    X_train = X[int(X.shape[0]*rate):]\n",
    "    Y_train = Y[int(Y.shape[0]*rate):]\n",
    "    X_val = X[:int(X.shape[0]*rate)]\n",
    "    Y_val = Y[:int(Y.shape[0]*rate)]\n",
    "    Z_val = Z[:int(Z.shape[0]*rate)]\n",
    "    return X_train, Y_train, X_val, Y_val,Z_val\n",
    "\n",
    "def buildModel(train_x,train_y,bs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_length=train_x.shape[1],input_dim= train_x.shape[2],return_sequences=True))\n",
    "    model.add(LSTM(10,return_sequences=True))\n",
    "    model.add(LSTM(10,return_sequences=True))\n",
    "    model.add(LSTM(10))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.summary()\n",
    "    callback = EarlyStopping(monitor=\"loss\", patience=10, verbose=1, mode=\"auto\")\n",
    "    model.fit(train_x,train_y, epochs=1000, batch_size=bs, validation_split=0.1, callbacks=[callback])\n",
    "    return model,[10,10,10,10,0]\n",
    "\n",
    "def predict(model,layer,val_x,val_y,val_z,x,y,name):\n",
    "    a=range(0,val_y.shape[0])\n",
    "    val_y=val_y.reshape(-1)\n",
    "    val_z=val_z.reshape(-1)\n",
    "    plt.plot(a,val_y)\n",
    "    b=[]\n",
    "    co=0\n",
    "    for i in range(0,val_x.shape[0]):\n",
    "        temp=val_x[i]\n",
    "        temp=temp.reshape(1,x,19)\n",
    "        z=int(model.predict(temp, verbose=0))\n",
    "        if val_y[i]>=val_z[i] and z>=val_z[i]:\n",
    "            co=co+1\n",
    "        if val_y[i]<val_z[i] and z<val_z[i]:\n",
    "            co=co+1\n",
    "        b.append(z)\n",
    "    b=np.array(b)\n",
    "    b=b.reshape(-1)\n",
    "    plt.plot(a,b)\n",
    "    acc=100*(co/val_x.shape[0])\n",
    "    plt.savefig(name+'img/'+str(layer[0])+'+'+str(layer[1])+'+'+str(layer[2])+'+'+str(layer[3])+'+'+str(layer[4])+'+'+'ac,'+str(acc)+\"%\"+'+'+'lb,'+str(x)+'+'+'bs,'+str(y)+'.jpg')\n",
    "    plt.clf()\n",
    "    return str(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:40: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "C:\\Users\\admin\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:68: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(10, input_shape=(21, 15), return_sequences=True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 21, 10)            1040      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 21, 10)            840       \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 21, 10)            840       \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10)                840       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 3,571\n",
      "Trainable params: 3,571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1813 samples, validate on 202 samples\n",
      "Epoch 1/1000\n",
      "1813/1813 [==============================] - 4s 2ms/step - loss: 901.0842 - val_loss: 706.8892\n",
      "Epoch 2/1000\n",
      "1813/1813 [==============================] - 1s 807us/step - loss: 780.6297 - val_loss: 628.5204\n",
      "Epoch 3/1000\n",
      "1813/1813 [==============================] - 1s 794us/step - loss: 726.8971 - val_loss: 597.8311\n",
      "Epoch 4/1000\n",
      "1813/1813 [==============================] - 1s 799us/step - loss: 696.1531 - val_loss: 571.1071\n",
      "Epoch 5/1000\n",
      "1813/1813 [==============================] - 1s 791us/step - loss: 668.5729 - val_loss: 546.6591\n",
      "Epoch 6/1000\n",
      "1813/1813 [==============================] - 1s 797us/step - loss: 643.0476 - val_loss: 523.7626\n",
      "Epoch 7/1000\n",
      "1813/1813 [==============================] - 1s 802us/step - loss: 619.1168 - val_loss: 502.4842\n",
      "Epoch 8/1000\n",
      "1813/1813 [==============================] - 1s 813us/step - loss: 596.5329 - val_loss: 482.5741\n",
      "Epoch 9/1000\n",
      "1813/1813 [==============================] - 2s 873us/step - loss: 575.2192 - val_loss: 463.5253\n",
      "Epoch 10/1000\n",
      "1813/1813 [==============================] - 2s 868us/step - loss: 555.0656 - val_loss: 445.5051\n",
      "Epoch 11/1000\n",
      "1813/1813 [==============================] - 2s 884us/step - loss: 535.9530 - val_loss: 428.6879\n",
      "Epoch 12/1000\n",
      "1813/1813 [==============================] - 2s 858us/step - loss: 517.8584 - val_loss: 412.7887\n",
      "Epoch 13/1000\n",
      "1813/1813 [==============================] - 1s 819us/step - loss: 500.7257 - val_loss: 397.7070\n",
      "Epoch 14/1000\n",
      "1813/1813 [==============================] - 2s 831us/step - loss: 484.4132 - val_loss: 383.5323\n",
      "Epoch 15/1000\n",
      "1813/1813 [==============================] - 2s 840us/step - loss: 469.0161 - val_loss: 369.9643\n",
      "Epoch 16/1000\n",
      "1813/1813 [==============================] - 2s 856us/step - loss: 454.3865 - val_loss: 357.3197\n",
      "Epoch 17/1000\n",
      " 576/1813 [========>.....................] - ETA: 0s - loss: 480.0714"
     ]
    }
   ],
   "source": [
    "lookback=21\n",
    "batch_size=32\n",
    "col_name=[\"1\",\"2\",\"3\",\"4\",\"5\",\"acc\",\"lookback\",\"batch_size\"]\n",
    "place_name=[\"雲林\",\"嘉義\",\"彰化\",\"台南\",\"高雄\",\"屏東\",\"台中\",\"苗栗\",\"桃園\",\"台北\"]\n",
    "\n",
    "for i in place_name:\n",
    "    \n",
    "    df=pd.DataFrame(columns=col_name)\n",
    "    data=[]\n",
    "    train,weather=readData(i)\n",
    "    train=concatData(train,weather)\n",
    "    temp=train\n",
    "    train=sta(train)\n",
    "    train_x1,train_y1,train_z1=buildTrain(train,lookback,1)\n",
    "    train_x2,train_y2,train_z2=buildTrain(temp,lookback,1)\n",
    "    train_x,train_y,train_z=train_x1,train_y2,train_z2\n",
    "    train_x,train_y,train_z= shuffle(train_x,train_y,train_z)\n",
    "    train_x,train_y, val_x, val_y ,val_z= splitData(train_x,train_y,train_z, 0.05)\n",
    "    model,layer=buildModel(train_x,train_y,batch_size)\n",
    "    pre=predict(model,layer,val_x,val_y,val_z,lookback,batch_size,i)\n",
    "    data.append({\"1\":layer[0],\"2\":layer[1],\"3\":layer[2],\"4\":layer[3],\"5\":layer[4],\"acc\":pre,\"lookback\":lookback,\"batch_size\":batch_size})\n",
    "    df=pd.concat([pd.DataFrame(data), df], ignore_index=True,sort=True)\n",
    "    df.to_csv(i+'data'+'(lookback  '+str(i)+')'+'(bs  '+str(j)+')'+'.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
